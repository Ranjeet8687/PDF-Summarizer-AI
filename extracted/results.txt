{
    "Results": {
        "cnn3": [
            {
                "text": "We first report the configuration which achieved the highest accuracy, followed by the search through the space of hyperparameters (using only our validation data set) leading to the optimal configuration. We close by demonstrating the ability of FF trained CNNs to implement Class Activation Maps, which is a method from the explainable AI toolbox.",
                "similarity": 0.9046024084091187
            }
        ],
        "cnn4": [
            {
                "text": "The results of our trials can be found in Figure 3 and a comparison of our model with other models on CIFAR-10 image classification can be found in Figure 4.\n\n| Metric | Trial 1 | Trial 2 | Trial 3 | NumberofParametersTrial 4 | Trial 5 | Mean |\n| - | - | - | - | - | - | - |\n| Val Accuracy (at 70%) | 13696 | 11360 | 11360 | 11360 | 9024 | 11360.0 |\n| Val Accuracy (at 80%) | 27852 | 51880 | 22636 | 37320 | 28588 | 33655.2 |\n| Highest Val Accuracy (%) | 83.4 | 84.6 | 84.6 | 84.5 | 83.2 | 84.1 |\n| Parameters at Highest Accuracy | 74564 | 73720 | 57808 | 66440 | 40960 | 62698.4 |\n\n\nFigure 3: Table displaying the number of parameters required to achieve different validation accuracies on CIFAR-10 over 5 different trials with the same hyperparameters.",
                "similarity": 0.9121243953704834
            }
        ],
        "cnn5": [
            {
                "text": "1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. \"72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data.\" SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. \"Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network.\" 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n4. Xing, Jinming. \"Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling.\" arXiv preprint arXiv:2411.07482 (2024).\n5. Veli\u010dkovi\u0107, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. \"Inductive representation learning on large graphs.\" Advances in neural information processing systems 30 (2017).\n7. Xing, Jinming, Can Gao, and Jie Zhou. \"Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis.\" Applied Soft Computing 124 (2022): 109025.\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. \"Parameterized maximum-entropy-based three-way approximate attribute reduction.\" International Journal of Approximate Reasoning 151 (2022): 85-100.\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. \"FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders.\" arXiv preprint arXiv:2412.01979 (2024).\n10. S. R. Livingstone and F. A. Russo, \"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),\" PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. \"Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning.\" arXiv preprint arXiv:2412.17271 (2024).\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, \"End-to-End Text-Dependent Speaker Verification,\" in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115\u20135119.\n13. S. Hochreiter and J. Schmidhuber, \"Long Short-Term Memory,\" Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, \"Learning to Forget: Continual Prediction with LSTM,\" Neural Computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. \"Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective.\" arXiv preprint arXiv:2411.14654 (2024).",
                "similarity": 0.8521064519882202
            }
        ],
        "cnn1": [
            {
                "text": "1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642\u20133649. IEEE (2012)\n\n2. Cire\u015fan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013, pp. 411\u2013418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire\u015fan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135\u20131139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279\u20132301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257\u2013260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221\u2013231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725\u20131732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097\u20131105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541\u2013551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278\u20132324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685\u2013696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224\u2013229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553\u20132561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157\u20132162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision\u2013ECCV 2014, pp. 818\u2013833. Springer (2014)",
                "similarity": 0.8521064519882202
            }
        ],
        "cnn2": [
            {
                "text": "[1] Joakim And\u00e9n and St\u00e9phane Mallat. Deep scattering spectrum. Signal Processing, IEEE Transactions on, 62(16):4114\u20134128, 2014.\n\n[2] Joan Bruna and St\u00e9phane Mallat. Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1872\u20131886, 2013.\n\n[3] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3): 273\u2013297, 1995.\n\n[4] Joan Bruna Estrach. Scattering representations for recognition.\n\n[5] Kaiser Gerald. A friendly guide to wavelets, 1994.\n\n[6] B Boser Le Cun, John S Denker, D Henderson, Richard E Howard, W Hubbard, and Lawrence D Jackel. Handwritten digit recognition with a back-propagation network. In Advances in neural information processing systems. Citeseer, 1990.\n\n[7] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.\n\n[8] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, 2015.\n\n[9] St\u00e9phane Mallat. Group invariant scattering. Communications on Pure and Applied Mathematics, 65(10):1331\u20131398, 2012.\n\n[10] St\u00e9phane Mallat. Understanding deep convolutional networks. arXiv preprint arXiv:1601.04920, 2016.",
                "similarity": 0.8521064519882202
            }
        ]
    }
}