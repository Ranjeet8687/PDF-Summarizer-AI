    
            I am providing a JSON containing text excerpts that match a user's query with a similarity score of 0.85 or higher. Your task is to generate concise, well-structured, and contextually relevant headdings and summaries based on this content.

            Instructions:
            - Heading should be from "sub-headding" key value of the given json and remove any Initial number given before the headding text.
            - Multiple "sub-headding" could have same heading so provide multiple heading and summries but they should not be same.
            - The headding and summaries should be clear, concise, and directly relevant to the userâ€™s query.
            - Retain the most important insights while eliminating redundancy.
            - Ensure the summary is logically structured and coherent.
            - If multiple texts provide different perspectives, synthesize them into a unified and meaningful response.
            - Avoid unnecessary details, focusing only on highly relevant information.
            Input:
                [
    {
        "text": "As the name implies, the convolutional layer plays a vital role in how CNNs operate. The layers parameters focus around the use of learnable kernels.\n\nThese kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map. These activation maps can be visualised, as seen in Figure 3.\n\nAs we glide through the input, the scalar product is calculated for each value in that kernel. (Figure 4) From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as activations.\n\n| Input Vector |   |   |   |   |   | Pooled Vector |   |   | Kernel |   |   | Destination Pixel |\n|--------------|---|---|---|---|---|----------------|---|---|--------|---|---|-------------------|\n| 0            | 0 | 0 | 0 | 0 | 0 | 0              | 0 | 0 | 4      | 0 | 0 |                   |\n| 0            | 1 | 2 | 1 | 1 | 2 | 0              | 1 | 2 | 0      | 0 | 0 | -8                |\n| 0            | 1 | 1 | 1 | 1 | 1 | 0              | 1 | 1 | 0      | 0 | -4|                   |\n| 1            | 0 | 0 | 0 | 0 | 0 |                |   |   |        |   |   |                   |\n| 0            | 0 | 1 | 1 | 1 | 0 |                |   |   |        |   |   |                   |\n| 0            | 1 | 1 | 1 | 1 | 1 |                |   |   |        |   |   |                   |\n\nFig. 4: A visual representation of a convolutional layer. The centre element of the kernel is placed over the input vector, of which is then calculated and replaced with a weighted sum of itself and any nearby pixels.\n\nEvery kernel will have a corresponding activation map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n\nAs we alluded to earlier, training ANNs on inputs such as images results in models of which are too big to train effectively. This comes down to the fully-connected manner of standard ANN neurons, so to mitigate against this every neuron in a convolutional layer is only connected to small region of the input volume. The dimensionality of this region is commonly referred to as the receptive field size of the neuron. The magnitude of the connectivity through the depth is nearly always equal to the depth of the input.\n\nFor example, if the input to the network is an image of size 64 \u00d7 64 \u00d7 3 (a RGB-coloured image with a dimensionality of 64 \u00d7 64) and we set the receptive field size as 6 \u00d7 6, we would have a total of 108 weights on each neuron within the convolutional layer. (6 \u00d7 6 \u00d7 3 where 3 is the magnitude of connectivity across the depth of the volume) To put this into perspective, a standard neuron seen in other forms of ANN would contain 12,288 weights each.\n\nConvolutional layers are also able to significantly reduce the complexity of the model through the optimisation of its output. These are optimised through three hyperparameters, the depth, the stride and setting zero-padding.\n\nIntroduction to Convolutional Neural Networks    7\n\nThe depth of the output volume produced by the convolutional layers can be manually set through the number of neurons within the layer to a the same region of the input. This can be seen with other forms of ANNs, where the all of the neurons in the hidden layer are directly connected to every single neuron beforehand. Reducing this hyperparameter can significantly minimise the total number of neurons of the network, but it can also significantly reduce the pattern recognition capabilities of the model.\n\nWe are also able to define the stride in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example if we were to set a stride as 1, then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n\nZero-padding is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes.\n\nIt is important to understand that through using these techniques, we will alter the spatial dimensionality of the convolutional layers output. To calculate this, you can make use of the following formula:\n\n$$(V - R) + 2Z \\over S + 1$$\n\nWhere V represents the input volume size (height\u00d7width\u00d7depth), R represents the receptive field size, Z is the amount of zero padding set and S referring to the stride. If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input.\n\nDespite our best efforts so far we will still find that our models are still enormous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer.\n\nParameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer.\n\nAs a result of this as the backpropagation stage occurs, each neuron in the output will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.\n\n8      Keiron O'Shea et al.",
        "sub_heading": "2.2 Convolutional layer",
        "collection_name": "cnn1",
        "similarity": 0.8848916292190552
    },
    {
        "text": "As the name implies, the convolutional layer plays a vital role in how CNNs operate. The layers parameters focus around the use of learnable kernels.\n\nThese kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map. These activation maps can be visualised, as seen in Figure 3.\n\nAs we glide through the input, the scalar product is calculated for each value in that kernel. (Figure 4) From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as activations.\n\n| Input Vector | | | | | | Pooled Vector | | | Kernel | | | Destination Pixel |\n| - | - | - | - | - | - | - | - | - | - | - | - | - |\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | -8 |\n| 0 | 1 | 2 | 1 | 1 | 2 | 0 | 1 | 2 | 0 | 0 | 0 | |\n| 0 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | -4 | |\n| 1 | 0 | 0 | 0 | 0 | 0 | | | | | | | |\n| 0 | 0 | 1 | 1 | 1 | 0 | | | | | | | |\n| 0 | 1 | 1 | 1 | 1 | 1 | | | | | | | |\n\n\nFig. 4: A visual representation of a convolutional layer. The centre element of the kernel is placed over the input vector, of which is then calculated and replaced with a weighted sum of itself and any nearby pixels.\n\nEvery kernel will have a corresponding activation map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n\nAs we alluded to earlier, training ANNs on inputs such as images results in models of which are too big to train effectively. This comes down to the fully-connected manner of standard ANN neurons, so to mitigate against this every neuron in a convolutional layer is only connected to small region of the input volume. The dimensionality of this region is commonly referred to as the receptive field size of the neuron. The magnitude of the connectivity through the depth is nearly always equal to the depth of the input.\n\nFor example, if the input to the network is an image of size 64 \u00d7 64 \u00d7 3 (a RGB-coloured image with a dimensionality of 64 \u00d7 64) and we set the receptive field size as 6 \u00d7 6, we would have a total of 108 weights on each neuron within the convolutional layer. (6 \u00d7 6 \u00d7 3 where 3 is the magnitude of connectivity across the depth of the volume) To put this into perspective, a standard neuron seen in other forms of ANN would contain 12,288 weights each.\n\nConvolutional layers are also able to significantly reduce the complexity of the model through the optimisation of its output. These are optimised through three hyperparameters, the depth, the stride and setting zero-padding.\n\nIntroduction to Convolutional Neural Networks    7\n\nThe depth of the output volume produced by the convolutional layers can be manually set through the number of neurons within the layer to a the same region of the input. This can be seen with other forms of ANNs, where the all of the neurons in the hidden layer are directly connected to every single neuron beforehand. Reducing this hyperparameter can significantly minimise the total number of neurons of the network, but it can also significantly reduce the pattern recognition capabilities of the model.\n\nWe are also able to define the stride in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example if we were to set a stride as 1, then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n\nZero-padding is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes.\n\nIt is important to understand that through using these techniques, we will alter the spatial dimensionality of the convolutional layers output. To calculate this, you can make use of the following formula:\n\n$$(V - R) + 2Z \\over S + 1$$\n\nWhere V represents the input volume size (height\u00d7width\u00d7depth), R represents the receptive field size, Z is the amount of zero padding set and S referring to the stride. If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input.\n\nDespite our best efforts so far we will still find that our models are still enormous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer.\n\nParameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer.\n\nAs a result of this as the backpropagation stage occurs, each neuron in the output will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.\n\n8      Keiron O'Shea et al.",
        "sub_heading": "2.2 Convolutional layer",
        "collection_name": "cnn1",
        "similarity": 0.8848916292190552
    },
    {
        "text": "As noted earlier, CNNs primarily focus on the basis that the input will be comprised of images. This focuses the architecture to be set up in way to best suit the need for dealing with the specific type of data.\n\n4      Keiron O'Shea et al.\n\nOne of the key differences is that the neurons that the layers within the CNN are comprised of neurons organised into three dimensions, the spatial dimensionality of the input (height and the width) and the depth. The depth does not refer to the total number of layers within the ANN, but the third dimension of a activation volume. Unlike standard ANNS, the neurons within any given layer will only connect to a small region of the layer preceding it.\n\nIn practice this would mean that for the example given earlier, the input 'volume' will have a dimensionality of 64 \u00d7 64 \u00d7 3 (height, width and depth), leading to a final output layer comprised of a dimensionality of 1 \u00d7 1 \u00d7 n (where n represents the possible number of classes) as we would have condensed the full input dimensionality into a smaller volume of class scores filed across the depth dimension.",
        "sub_heading": "2 CNN architecture",
        "collection_name": "cnn1",
        "similarity": 0.8355773091316223
    },
    {
        "text": "As noted earlier, CNNs primarily focus on the basis that the input will be comprised of images. This focuses the architecture to be set up in way to best suit the need for dealing with the specific type of data.\n\n4      Keiron O'Shea et al.\n\nOne of the key differences is that the neurons that the layers within the CNN are comprised of neurons organised into three dimensions, the spatial dimensionality of the input (height and the width) and the depth. The depth does not refer to the total number of layers within the ANN, but the third dimension of a activation volume. Unlike standard ANNS, the neurons within any given layer will only connect to a small region of the layer preceding it.\n\nIn practice this would mean that for the example given earlier, the input 'volume' will have a dimensionality of 64 \u00d7 64 \u00d7 3 (height, width and depth), leading to a final output layer comprised of a dimensionality of 1 \u00d7 1 \u00d7 n (where n represents the possible number of classes) as we would have condensed the full input dimensionality into a smaller volume of class scores filed across the depth dimension.",
        "sub_heading": "2 CNN architecture",
        "collection_name": "cnn1",
        "similarity": 0.8355773091316223
    },
    {
        "text": "Convolutional Neural Networks (CNNs), introduced by Le Cun et al. [6] are a class of biologically inspired neural networks which solve equation (1) by passing X through a series of convolutional filters and simple non-linearities. They have shown remarkable results in a wide variety of machine learning problems [8]. Figure 1 shows a typical CNN architecture.\n\nA convolutional neural network has a hierarchical architecture. Starting from the input signal x, each subsequent layer xj is computed as\n\n$$x_j = \\rho W_j x_{j-1} \\tag{5}$$\n\nHere Wj is a linear operator and \u03c1 is a non-linearity. Typically, in a CNN, Wj is a convolution, and \u03c1 is a rectifier max(x, 0) or sigmoid 1/1+exp(\u2212x). It is easier to think of the operator Wj as a stack of convolutional filters. So the layers are filter maps and each layer can be written as a sum of convolutions of the previous layer.\n\n$$x_j(u, k_j) = \\rho \\left( \\sum_k (x_{j-1}(., k) * W_{j,k_j}(., k))(u) \\right) \\tag{6}$$\n\nHere * is the discrete convolution operator:\n\n$$(f * g)(x) = \\sum_{u=-\\infty}^{\\infty} f(u)g(x - u) \\tag{7}$$\n\nThe optimization problem defined by a convolutional neural network is highly non-convex. So typically, the weights Wj are learned by stochastic gradient descent, using the backpropagation algorithm to compute gradients.\n\nFigure 1: Architecture of a Convolutional Neural Network (from LeCun et al. [7])\n\n| Layer | Description | Size/Maps |\n|-------|-------------|-----------|\n| INPUT | Input layer | 32x32 |\n| C1 | Feature maps | 6@28x28 |\n| S2 | Subsampling | 6@14x14 |\n| C3 | Feature maps | 16@10x10 |\n| S4 | Subsampling | 16@5x5 |\n| C5 | Fully connected layer | 120 |\n| F6 | Fully connected layer | 84 |\n| OUTPUT | Output layer | 10 |\n\nConvolutions -> Subsampling -> Convolutions -> Subsampling -> Full connection -> Gaussian connections",
        "sub_heading": "1.5 Convolutional Neural Networks",
        "collection_name": "cnn2",
        "similarity": 0.9026693105697632
    },
    {
        "text": "The scattering transform described in the previous section provides a simple view of a general convolutional neural netowrk. While it provides intuition behind the working of CNNs, the transformation suffers from high variance and loss of information because we only consider single channel convolutions. To analyze the properties of general CNN architectures, we must allow for channel combinations. Mallat [10] extends previously introduced tools to develop a mathematical framework for this analysis. The theory is, however, out of the scope of this paper. At a high level, the extension is achieved by replacing the requirement of contractions and invariants to translations by contractions along adaptive groups of local symmetries. Further, the wavelets are replaced by adapted filter weights similar to deep learning models.",
        "sub_heading": "5 General Convolutional Neural Network Architectures",
        "collection_name": "cnn2",
        "similarity": 0.8422204256057739
    }
]

            Note:  Do not include text like I understand or here is your summary and Do not mension heading at start.
            Output Format:
            Provide a concise, headding and well-structured, contextually relevant summary based on the retrieved texts.
            in fornt of heading put a 2nd Heading (##) like Markdown format and then nextline then summary normal text give it as usual, Multiple "sub-headding" could have same heading so provide multiple heading and summries but they should not be same.
        